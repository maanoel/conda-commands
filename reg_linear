#A aprendizagem de máquina é uma técnica que permite que um modelo aprenda a realizar tarefas a partir de dados, sem que sejam explícitamente programados para realizar essas tarefas. Aqui está um exemplo de uma função de aprendizagem de máquina que utiliza o algoritmo de regressão linear simples para treinar um modelo de previsão de saída contínua a partir de um conjunto de entrada e saída:

import numpy as np

def fit(X, y):
  # Inicializa os pesos w com valores aleatórios
  w = np.random.randn(X.shape[1])

  # Define a taxa de aprendizado
  eta = 0.01

  # Executa o algoritmo de treinamento por 1000 iterações
  for i in range(1000):
    # Calcula a saída prevista do modelo para as amostras de entrada X
    y_pred = X.dot(w)

    # Calcula o erro entre a saída prevista e a saída real
    error = y_pred - y

    # Atualiza os pesos w usando o gradiente descendente
    w -= eta * (X.T.dot(error) / len(X))

  # Retorna os pesos treinados
  return w

def predict(X, w):
  # Calcula a saída prevista do modelo para as amostras de entrada X
  y_pred = X.dot(w)
  return y_pred

#Para usar essa função, basta fornecer um conjunto de entrada X e saída y de treinamento e chamar a função fit para treinar o modelo. Em seguida, você pode usar a função predict para realizar previsões usando o modelo treinado.

# Suponha que temos um conjunto de amostras de entrada X e saída y
X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])
y = np.array([5, 7, 9, 11])

# Treinamos o modelo usando o conjunto de treinamento
w = fit(X, y)

# Realizamos uma previsão usando o modelo treinado
x_test = np.array([5, 6])
y_pred = predict(x_test, w)
print(y_pred)  # imprime a previsão do modelo para as amostras de entrada x_test

import numpy as np
from keras.models import Sequential
from keras.layers import Dense

# Generate dummy data
x_train = np.random.random((1000, 20))
y_train = np.random.randint(2, size=(1000, 1))
x_test = np.random.random((100, 20))
y_test = np.random.randint(2, size=(100, 1))

# Build model
model = Sequential()
model.add(Dense(64, input_dim=20, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train model
model.fit(x_train, y_train, epochs=10, batch_size=128)

# Evaluate model
score = model.evaluate(x_test, y_test, batch_size=128)
print(score)


-------
import numpy as np

def sigmoid(x):
  return 1 / (1 + np.exp(-x))

def generate_neural_network(inputs, weights):
  # Generate hidden layer with random weights
  hidden_layer_weights = np.random.randn(inputs.shape[1], 4)
  
  # Generate output layer with random weights
  output_layer_weights = np.random.randn(4, 1)
  
  # Return generated weights as a list
  return [hidden_layer_weights, output_layer_weights]

def predict(inputs, weights):
  # Generate new neural network
  generated_weights = generate_neural_network(inputs, weights)
  
  # Use generated weights to make predictions
  hidden_layer_inputs = np.dot(inputs, generated_weights[0])
  hidden_layer_outputs = sigmoid(hidden_layer_inputs)
  output_layer_inputs = np.dot(hidden_layer_outputs, generated_weights[1])
  return sigmoid(output_layer_inputs)

def main():
  inputs = np.array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])
  weights = np.array([0.5, 0.5, 0.5])

  predictions = predict(inputs, weights)
  print(predictions)

if __name__ == '__main__':
  main()
